[{"authors":null,"categories":null,"content":"Yury Maximov is a staff research scientist and project manager at the Theoretical Division of Los Alamos National Laboratory (LANL). His research interests include operations research, machine learning, network science, and statistics. He is a part of the Advanced Network Science Initiative (ANSI) at LANL and leads LANL-ANSI research on data-driven decision making for emergency control and protection of US critical infrastructure.  Yury's research interest also include Monte-Carlo methods, robust optimization, machine learning, physical and engineering modeling.     Download my resumé.\n","date":1623283200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1623283200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://yury-maximov.github.io/author/yury-maximov/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yury-maximov/","section":"authors","summary":"Yury Maximov is a staff research scientist and project manager at the Theoretical Division of Los Alamos National Laboratory (LANL). His research interests include operations research, machine learning, network science, and statistics.","tags":null,"title":"Yury Maximov","type":"authors"},{"authors":null,"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1607817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://yury-maximov.github.io/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"          Image Credit: Wikipedia    Table of Contents  Course Abstract What you will learn Lecture notes, slides, home assignments Meet your instructor FAQs    Course Abstract This is the MS./Ph.D. level 6-credit course is an application-oriented introduction to numerical optimization. It will focus on modeling real-world engineering tasks as optimization problems and using state-of-the-art optimization techniques to solve these problems. The course will start with the basics of convex analysis; later on, we move to iterative optimization algorithms to solve convex optimization problems. The last part of the course focuses on real-world engineering applications and provides a student with state-of-the-art techniques to solve them.\nThe course is recommended as an elective for the students of engineering and data science master programs.\nWhat you will learn  modern iterative optimization algorithms techniques which are sufficient to formulate and solve real-world problems.  Lecture notes, slides, home assignments According to the university policy, lecture notes, videos and slides are posted online on Canvas and accessible to all Skoltech students. Course TAs and I would be happy to address any questions prior, during, or after the course.\nMeet your instructor Yury Maximov FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Each second fall term.\n ","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"1e7f102d995382d4bde97869e6130f13","permalink":"https://yury-maximov.github.io/courses/example-10/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example-10/","section":"courses","summary":"MA06123, Skolkovo Insitute of Science and Technology, 2018-2020","tags":null,"title":"Large Scale Optimization and Applications","type":"book"},{"authors":null,"categories":null,"content":"          Image Credit: TowardDataScience.com    Table of Contents  Course Abstract What you will learn Lecture notes, slides, home assignments Meet your instructor FAQs    Course Abstract This is an introductory MS/Ph.D. level 3 credit course in the theory of machine learning. Our primary focus is a theoretical analysis of prediction methods, including statistical and computational aspects. There are no formal prerequisites for this class. But we will assume a significant level of mathematical maturity. This means an understanding of linear algebra, analysis, and probability. Convex optimization and machine learning will be extremely helpful but is not strictly necessary. Despite the theoretical nature of the course, students will be given a lot of practical exercises. Thus we expect knowledge of at least one programming language (Python, Julia, R, or C/C++).\nWhat you will learn  basic of statistical learning theory, abilities and limitations of machine learning algorithms main tools to analyse, implement and test machine learning methods  Lecture notes, slides, home assignments According to the university policy, lecture notes, videos and slides are posted online on Canvas and accessible to all Skoltech students. Course TAs and I would be happy to address any questions prior, during, or after the course.\nMeet your instructor Yury Maximov FAQs Are there prerequisites? We assume some basic knowledge of linear algebra, analysis, and probability. Convex optimization and machine learning will be extremely helpful but is not strictly necessary. Programming skills are required (C/C++/Python or Julia).\n How often do the courses run? Once in two years (the spring term).\n  Begin the course   ","date":1609459200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609459200,"objectID":"ab3ca526b659efb1bf96475d3285da57","permalink":"https://yury-maximov.github.io/courses/example-20/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example-20/","section":"courses","summary":"MA030417, Skolkovo Insitute of Science and Technology and the Higher School of Economics","tags":null,"title":"Statistical Learning Theory","type":"book"},{"authors":null,"categories":null,"content":"          Image Credit: Wikipedia    Table of Contents  Course Abstract Meet your instructor    Course Abstract I was honored to be invited to the Department of Mathematics of the University of Arizona, Tucson, to deliver 9 lectures on convex optimization methods in 2019. In my lectures I revealed connections of optimization methods with the optimal control, machine learning and statistical estimation.\nMeet your instructor Yury Maximov ","date":1546300800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1546300800,"objectID":"696a905816254ef4093c062288fc49d2","permalink":"https://yury-maximov.github.io/courses/example-30/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/courses/example-30/","section":"courses","summary":"Math 584b/581b, University of Arizona, 9 invited lectures, 2019","tags":null,"title":"Theoretical Foundations of Applied Mathematics","type":"book"},{"authors":null,"categories":null,"content":"About ESG stands for Environmental, Social, and Corporate Governance factors, which is a set of standards for company operations that are consistent with sustainable development goals. Socially conscious investors use ESG standards to screen potential investments and examine their investment strategies.\nJointly with the experts of the New Economic School we work on improving investment decisions by \n detecting Greenwashing with advanced machine learning techniques analyzing ESG-induced financial risks and estimating ESG bonds' fair price.  ","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"e3d4bd6b6060bfab78087b4160773870","permalink":"https://yury-maximov.github.io/project/internal-project-30/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/project/internal-project-30/","section":"project","summary":"About ESG stands for Environmental, Social, and Corporate Governance factors, which is a set of standards for company operations that are consistent with sustainable development goals. Socially conscious investors use ESG standards to screen potential investments and examine their investment strategies.","tags":["Power Grids","Optimization and Statistics"],"title":"Enviromental-, Society-, and Governance- (ESG) Risk Analysis","type":"project"},{"authors":null,"categories":null,"content":"About Energy blackouts cost the nation over twenty billion dollars annually and provide a vital security thread for critical infrastructure security. Such blackouts are mainly caused by weather-induced or human-made extreme events (snowstorms, cyber-attacks, etc.). To maintain the safe and secure operation of power grids in the presence of extreme events, we design advanced real-time analytical and data-driven methods that are supported by extensive theoretical and empirical studies. In particular, our algorithms cover all stages of emergency control and protection: simulation, prediction, detection, and mitigation of extreme events. Our methods are equally focused on convenience for real-life operation practice, and solid theoretical justification guarantees their worst-case efficiency. Our efforts are supported by the Office of Electricity of the U.S. Department of Energy.\nUS DOE Office of Electricity Sponsored Projects 1. Robust Real-Time Control, Monitoring, and Protection of Large-Scale Power Grids in Response to Extreme Events, PI: Yury Maximov Collaboration: Massachusetts Institute of Technology, University of Wisconsin-Madison, Lawrence Livermore National Laboratory\n 2. Emergency Monitoring and Control Through New Technologies and Analytics, PI: Yury Maximov Collaboration: Massachusetts Institute of Technology, Pacific Northwest National Laboratory\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"6e32471be9eaec303577f4958beda20d","permalink":"https://yury-maximov.github.io/project/internal-project-10/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/project/internal-project-10/","section":"project","summary":"About Energy blackouts cost the nation over twenty billion dollars annually and provide a vital security thread for critical infrastructure security. Such blackouts are mainly caused by weather-induced or human-made extreme events (snowstorms, cyber-attacks, etc.","tags":["Power Grids"],"title":"Extreme Events in Power Grids","type":"project"},{"authors":null,"categories":null,"content":"About Importance sampling is a popular technique for estimating high-dimensional distributions, while only having samples generated from a different distribution than the distribution of interest. In our research we are working constructing optimal importance samplers and revealing interesting two-way connections of importance sampling and convex optimization. Finally, we pay a special attention to applications of importance sampling for applications. Some of our relevant papers are outlined here.\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"cefae8bd2b283404b4366a67ca2175ca","permalink":"https://yury-maximov.github.io/project/internal-project-20/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/project/internal-project-20/","section":"project","summary":"About Importance sampling is a popular technique for estimating high-dimensional distributions, while only having samples generated from a different distribution than the distribution of interest. In our research we are working constructing optimal importance samplers and revealing interesting two-way connections of importance sampling and convex optimization.","tags":["Optimization and Statistics"],"title":"Importance Sampling and Optimization","type":"project"},{"authors":["Aleksandr Lukashevich","Yury Maximov"],"categories":null,"content":"","date":1623283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623283200,"objectID":"b3ec3445e8dafd56433f64e1ac10d0e7","permalink":"https://yury-maximov.github.io/publication/j30-lukashevich-2021/","publishdate":"2021-06-10T00:00:00Z","relpermalink":"/publication/j30-lukashevich-2021/","section":"publication","summary":"Electricity production currently generates approximately 25% of greenhouse gas emissions in the USA. Thus, increasing the amount of renewable energy is a key step to carbon neutrality. However, integrating a large amount of fluctuating renewable generation is a significant challenge for power grid operating and planning. Grid reliability, i.e., an ability to meet operational constraints under power fluctuations, is probably the most important of them. In this letter, we propose computationally efficient and accurate methods to estimate the probability of line overflow, i.e., reliability constraints violation, under a known distribution of renewable energy generation. To this end, we investigate an importance sampling approach, a flexible extension of Monte-Carlo methods, which adap- tively changes the sampling distribution to generate more samples near the reliability boundary. The approach allows to estimate overload probability in real-time based only on a few dozens of random samples, compared to thou- sands required by the plain Monte-Carlo. Our study focuses on high voltage direct current power transmission grids with linear reliability constraints on power injections and line currents.  We propose a novel theoretically justified physics-informed adaptive importance sampling algorithm and compare its performance to state-of-the-art methods on multiple IEEE power grid test cases.","tags":null,"title":"Power Grid Reliability Estimation via Adaptive Importance Sampling","type":"publication"},{"authors":["Aleksandra Burashnikova","Yury Maximov","Marianne Clausel","Charlotte Laclau","Franck Iutzeler","Massih-Reza Amini"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"203fc03a8de7e7aab450dfccac6fd1dc","permalink":"https://yury-maximov.github.io/publication/j25-amini-2020/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/j25-amini-2020/","section":"publication","summary":"In this paper, we propose a theoretically supported sequential strategy for training a large-scale Recommender System (RS) over implicit feedback, mainly in the form of clicks. The proposed approach consists in minimizing pairwise ranking loss over blocks of consecutive items constituted by a sequence of non-clicked items followed by a clicked one for each user. We present two variants of this strategy where model parameters are updated using either the momentum method or a gradient-based approach. To prevent updating the parameters for an abnormally high number of clicks over some targeted items (mainly due to bots), we introduce an upper and a lower threshold on the number of updates for each user. These thresholds are estimated over the distribution of the number of blocks in the training set. They affect the decision of RS by shifting the distribution of items that are shown to the users. Furthermore, we provide a convergence analysis of both algorithms and demonstrate their practical efficiency over six large-scale collections with respect to various ranking measures and computational time.","tags":null,"title":"Learning over no-Preferred and Preferred Sequence of items for Robust Recommendation","type":"publication"},{"authors":["Sumit Sidana","Mikhail Trofimov","0leh Horodnytskyi","Charlotte Laclau","Yury Maximov","Massih-Reza Amini"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"cf1c830c2f9657bd3e4fb4c0ecb08654","permalink":"https://yury-maximov.github.io/publication/j24-sidana-2020/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/j24-sidana-2020/","section":"publication","summary":"In this paper, we propose a theoretically supported sequential strategy for training a large-scale Recommender System (RS) over implicit feedback, mainly in the form of clicks. The proposed approach consists in minimizing pairwise ranking loss over blocks of consecutive items constituted by a sequence of non-clicked items followed by a clicked one for each user. We present two variants of this strategy where model parameters are updated using either the momentum method or a gradient-based approach. To prevent updating the parameters for an abnormally high number of clicks over some targeted items (mainly due to bots), we introduce an upper and a lower threshold on the number of updates for each user. These thresholds are estimated over the distribution of the number of blocks in the training set. They affect the decision of RS by shifting the distribution of items that are shown to the users. Furthermore, we provide a convergence analysis of both algorithms and demonstrate their practical efficiency over six large-scale collections with respect to various ranking measures and computational time.","tags":null,"title":"User preference and embedding learning with implicit feedback for recommender systems","type":"publication"},{"authors":["Anton Anikin","Alexander Gasnikov","Alexander Gornov","Dmitry Kamzolov","Yury Maximov","Yurii Nesterov"],"categories":null,"content":"","date":1608422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608422400,"objectID":"aa007078f8762dbad47704cd3d0e0546","permalink":"https://yury-maximov.github.io/publication/j26-nesterov-2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/j26-nesterov-2020/","section":"publication","summary":"Over the last two decades, the PageRank problem has received increased interest from the academic community as an efficient tool to estimate web-page importance in information retrieval. Despite numerous developments, the design of efficient optimization algorithms for the PageRank problem is still a challenge. This paper proposes three new algorithms with a linear time complexity for solving the problem over a bounded-degree graph. The idea behind them is to set up the PageRank as a convex minimization problem over a unit simplex, and then solve it using iterative methods with small iteration complexity. Our theoretical results are supported by an extensive empirical justification using real-world and simulated data.","tags":null,"title":"Efficient numerical methods to solve sparse linear equations with application to PageRank","type":"publication"},{"authors":["Yury Maximov","吳恩達"],"categories":["Demo","教程"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://yury-maximov.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Valerii Likhosherstov","Yury Maximov","Michael Chertkov"],"categories":null,"content":"","date":1607558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607558400,"objectID":"3f1f8e23252a18f569337fc86fb736cd","permalink":"https://yury-maximov.github.io/publication/j27-chertkov-2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/j27-chertkov-2020/","section":"publication","summary":"We present a new family of zero-field Ising models over N binary variables/spins obtained by consecutive 'gluing' of planar and O(1)-sized components and subsets of at most three vertices into a tree. The polynomial time algorithm of the dynamic programming type for solving exact inference (computing partition function) and exact sampling (generating i.i.d. samples) consists of sequential application of an efficient (for planar) or brute-force (for $O(1)$-sized) inference and sampling to the components as a black box. To illustrate the utility of the new family of tractable graphical models, we first build a polynomial algorithm for inference and sampling of zero-field Ising models over $K_{33}$-minor-free topologies and over $K_5$-minor-free topologies—both of which are extensions of the planar zero-field Ising models—which are neither genus- nor treewidth-bounded. Second, we empirically demonstrate an improvement in the approximation quality of the $NP$-hard problem of inference over the square-grid Ising model in a node-dependent nonzero 'magnetic' field.","tags":null,"title":"Tractable minor-free generalization of planar zero-field Ising models","type":"publication"},{"authors":null,"categories":["R"],"content":"  R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"bf1eb249db79f10ace7d22321494165a","permalink":"https://yury-maximov.github.io/post/2020-12-01-r-rmarkdown/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/post/2020-12-01-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["Michael Chertkov","Vladimir Chernyak","Yury Maximov"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"9e79c44fb8a4efc5e588aedda2da3ce1","permalink":"https://yury-maximov.github.io/publication/j29-chernyak-2020/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/j29-chernyak-2020/","section":"publication","summary":"Graphical models represent multivariate and generally not normalized probability distributions. Computing the normalization factor, called the partition function, is the main inference challenge relevant to multiple statistical and optimization applications. The problem is \\#P-hard that is of an exponential complexity with respect to the number of variables. In this manuscript, aimed at approximating the partition function, we consider multi-graph models where binary variables and multivariable factors are associated with edges and nodes, respectively, of an undirected multi-graph. We suggest a new methodology for analysis and computations that combines the Gauge function technique with real stable polynomials. We show that the Gauge function, representing a single-out term in a finite sum expression for the partition function which achieves extremum at the so-called belief-propagation gauge, has a natural polynomial representation in terms of gauges/variables associated with edges of the multi-graph. Moreover, Gauge function can be used to recover the partition function through a sequence of transformations allowing appealing algebraic and graphical interpretations. Algebraically, one step in the sequence consists of the application of a differential operator over gauges associated with an edge. Graphically, the sequence is interpreted as a repetitive elimination/contraction of edges resulting in multi-graph models on decreasing in size (number of edges) graphs with the same partition function as in the original multi-graph model. Even though the complexity of computing factors in the sequence of the derived multi-graph models and respective Gauge functions grow exponentially with the number of eliminated edges, polynomials associated with the new factors remain bi-stable if the original factors have this property. Moreover, we show that BP estimations in the sequence do not decrease, each low-bounding the partition function.","tags":null,"title":"Gauges, loops, and polynomials for partition functions of graphical models","type":"publication"},{"authors":["Nikolay Stulov","Dejan J.Sobajic","Yury Maximov","Deepjyoti Deka","Michael Chertkov"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"400406ca6a267b6998cb3e3aa4537caa","permalink":"https://yury-maximov.github.io/publication/j23-stulov-2020/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/j23-stulov-2020/","section":"publication","summary":"Assuming that a generator is monitored by the system operator via a PMU device positioned at the generator’s terminal bus, we pose and resolve the question of the real-time, data-driven and automatic monitoring of the generator’s performance. We establish regimes of optimal performance for four complementary techniques ranging from the computationally light (a) Vector Auto-Regressive Model, suitable for normal, linear or almost linear regime, via (b) Long-Short-Term-Memory and (c) Neural ODE Deep Learning models, appropriate to monitor mildly nonlinear regimes, and finally to the (d) physics-informed model. For example, the physics-informed model is capable of fast identification of nonlinear transients and providing interpretable results, suitable, in particular, for corrective actions. The conclusions are reached in the result of validating the models on synthetic data generated in a realistic setting from an open-source, state-of-the-art modeling software. Advanced analysis is followed by a summary and conclusion suitable for the next step - validation of the hierarchy of the suggested data-driven schemes in the industry setting.","tags":null,"title":"Learning model of generator from terminal data","type":"publication"},{"authors":["Artem Mikhalev","Alexander Emchinov","Samuel Chevalier","Yury Maximov","Petr Vorobev"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"206f530a579960c4045457684d0a84bf","permalink":"https://yury-maximov.github.io/publication/c28-artem-2020/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/publication/c28-artem-2020/","section":"publication","summary":"Having actual models for power system components, such as generators and loads or auxiliary equipment, is vital for a correct assessment of the power system operating state as well as establishing stability margins. Often, however, a power system operator has limited information about the actual values for power system components' parameters. Even if the model is available, its operating parameters, as well as the control settings, are time-dependent and subject to a real-time identification. Ideally, these parameters should be identified from measurement data, such as PMU signals. However, it is challenging to do this from the ambient measurements in the absence of transient dynamics since the signal to noise ratio (SNR) for such signals is not necessarily big. In this paper, we design a Bayesian framework for on-line identification of power system components' parameters based on ambient phasor measurement unit (PMU) data, that has reliable performance for SNR as low as five and for certain parameters can give good estimations even for unit SNR. Finally, we support the framework by a robust and time-efficient numerical method. We illustrate the approach efficiency on a synchronous generator example.","tags":null,"title":"A Bayesian Framework for Power System Components Identification","type":"publication"},{"authors":["Valerii Likhosherstov","Yury Maximov","Michael Chertkov"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"7fb4d439e58120a0363360eed903787b","permalink":"https://yury-maximov.github.io/publication/c19-valera-2019/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/c19-valera-2019/","section":"publication","summary":"We call an Ising model tractable when it is possible to compute its partition function value (statistical inference) in polynomial time. The tractability also implies an ability to sample configurations of this model in polynomial time. The notion of tractability extends the basic case of planar zero-field Ising models. Our starting point is to describe algorithms for the basic case, computing partition function and sampling efficiently. Then, we extend our tractable inference and sampling algorithms to models whose triconnected components are either planar or graphs of \\\\(O(1)\\\\) size. In particular, it results in a polynomial-time inference and sampling algorithms for \\\\(K_{3,3}\\\\)(minor)-free topologies of zero-field Ising models—a generalization of planar graphs with a potentially unbounded genus.","tags":null,"title":"Inference and Sampling of \\(K_{3,3}\\)-free Ising Models","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-935786214', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$  renders as\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\n1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% callout note %}} ... {{% /callout %}}, it will render as an aside.\n{{% callout note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /callout %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}}  renders as\nClick to view the spoiler You found me!\n Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://yury-maximov.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Mikhail Krechetov","Jakub Marecek","Yury Maximov","Martin Takac"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"ed378d723dc20f534af82ebbe3ee54a2","permalink":"https://yury-maximov.github.io/publication/c17-misha-2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/c17-misha-2019/","section":"publication","summary":"Low-rank methods for semidefinite programming (SDP) have gained a lot of interest recently, especially in machine learning applications. Their analysis often involves determinant-based or Schatten norm penalties, which are difficult to implement in practice due to high computational efforts. In this paper, we propose Entropy-Penalized Semi-Definite Programming (EP-SDP), which provides a unified framework for a broad class of penalty functions used in practice to promote a low-rank solution. We show that EP-SDP problems admit an efficient numerical algorithm, having (almost) linear time complexity of the gradient computation; this makes it useful for many machine learning and optimization problems. We illustrate the practical efficiency of our approach on several combinatorial optimization and machine learning problems.","tags":null,"title":"Entropy-Penalized Semidefinite Programming","type":"publication"},{"authors":["Valerii Likhosherstov","Yury Maximov","Michael Chertkov"],"categories":null,"content":"","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"ff021ff5ce79fe78bd8166492f59da36","permalink":"https://yury-maximov.github.io/publication/p-21-likhosherstov-2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/p-21-likhosherstov-2019/","section":"publication","summary":"We present a new family of zero-field Ising models over N binary variables/spins obtained by consecutive \"gluing\" of planar and \\\\(O(1)\\\\)-sized components along with subsets of at most three vertices into a tree. The polynomial time algorithm of the dynamic programming type for solving exact inference (partition function computation) and sampling consists of a sequential application of an efficient (for planar) or brute-force (for \\\\(O(1)\\\\)-sized) inference and sampling to the components as a black box. To illustrate the utility of the new family of tractable graphical models, we first build an \\\\(O(N^{3/2})\\\\) algorithm for inference and sampling of the \\\\(K_5\\\\)-minor-free zero-field Ising models - an extension of the planar zero-field Ising models - which is neither genus- nor treewidth-bounded. Second, we demonstrate empirically an improvement in the approximation quality of the NP-hard problem of the square-grid Ising model (with non-zero field) inference.","tags":null,"title":"A New Family of Tractable Ising Models","type":"publication"},{"authors":["Aleksandra Burashnikova","Yury Maximov","Massih-Reza Amini"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"24005b01869ced53358ab4176091e706","permalink":"https://yury-maximov.github.io/publication/c20-burashnikova-2019/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/publication/c20-burashnikova-2019/","section":"publication","summary":"In this paper, we propose a theoretically founded sequential strategy for training large-scale Recommender Systems (RS) over implicit feedback mainly in the form of clicks. The proposed approach consists in minimizing pairwise ranking loss over blocks of consecutive items constituted by a sequence of non-clicked items followed by a clicked one for each user. Parameter updates are discarded if for a given user the number of sequential blocks is below or above some given thresholds estimated over the distribution of the number of blocks in the training set. This is to prevent from updating the parameters for an abnormally high number of clicks over some targeted items, mainly due to bots; or very few user interactions. Both scenarios affect the decision of RS and imply a shift over the distribution of items that are shown to the users. We provide a proof of convergence of the algorithm to the minimizer of the ranking loss, in the case where the latter is convex. Furthermore, experimental results on five large-scale collections demonstrate the efficiency of the proposed algorithm concerning the state-of-the-art approaches, both regarding different ranking measures and computation time.","tags":null,"title":"Sequential Learning over Implicit Feedback for Robust Large-Scale Recommender Systems","type":"publication"},{"authors":["Art Owen","Yury Maximov","Michael Chertkov"],"categories":null,"content":"","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"3b4abc59e899cb3872ac3a59aac779c6","permalink":"https://yury-maximov.github.io/publication/j18-owen-2019/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/publication/j18-owen-2019/","section":"publication","summary":"We consider importance sampling to estimate the probability \\\\(\\mu\\\\) of a union of \\\\(J\\\\) rare events \\\\(H_j\\\\) defined by a random variable \\\\(x\\\\). The sampler we study has been used in spatial statistics, genomics and combinatorics going back at least to Karp and Luby (1983). It works by sampling one event at random, then sampling \\\\(x\\\\) conditionally on that event happening and it constructs an unbiased estimate of \\\\(\\mu\\\\) by multiplying an inverse moment of the number of occuring events by the union bound. We prove some variance bounds for this sampler. For a sample size of \\\\(n\\\\), it has a variance no larger than \\\\(\\mu(\\bar \\mu - \\mu)/(n)\\\\) where \\\\(\\bar \\mu\\\\)is the union bound. It also has a coefficient of variation no larger than \\\\(\\sqrt{(J + J^{-1}-2)/(4n)}\\\\) regardless of the overlap pattern among the \\\\(J\\\\) events. Our motivating problem comes from power system reliability, where the phase differences between connected nodes have a joint Gaussian distribution and the \\\\(J\\\\)rare events arise from unacceptably large phase differences. In the grid reliability problems even some events defined by 5772 constraints in \\\\(326\\\\) dimensions, with probability below \\\\(10^{−22}\\\\), are estimated with a coefficient of variation of about 0.0024 with only \\\\(n = 10,000\\\\) sample values.","tags":null,"title":"Importance sampling the union of rare events with an application to power systems analysis","type":"publication"},{"authors":["Yury Maximov"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')     print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://yury-maximov.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://yury-maximov.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Andrii Riazanov","Yury Maximov","Michael Chertkov"],"categories":null,"content":"","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"4d02b3a04c503142ff2016e4d7a52287","permalink":"https://yury-maximov.github.io/publication/c14-andrei-2018/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/publication/c14-andrei-2018/","section":"publication","summary":"Belief Propagation algorithms are instruments used broadly to solve graphical model optimization and statistical inference problems. In the general case of a loopy Graphical Model, Belief Propagation is a heuristic which is quite successful in practice, even though its empirical success, typically, lacks theoretical guarantees. This paper extends the short list of special cases where correctness and/or convergence of a Belief Propagation algorithm is proven. We generalize the formulation of Min-Sum Network Flow problem by relaxing the flow conservation (balance) constraints and then proving that the Belief Propagation algorithm converges to the exact result.","tags":null,"title":"Belief Propagation Min-Sum Algorithm for Generalized Min-Cost Network Flow","type":"publication"},{"authors":["Yury Maximov","Massih-Reza Amini","Zaid Harchaoui"],"categories":null,"content":"","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519862400,"objectID":"d4fa21ca87caa7ca78f4300ea5415e3d","permalink":"https://yury-maximov.github.io/publication/j16-zaid-2018/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/publication/j16-zaid-2018/","section":"publication","summary":"We propose Rademacher complexity bounds for multi-class classifiers trained with a two-step semi-supervised model. In the first step, the algorithm partitions the partially labeled data and then identifies dense clusters containing k predominant classes using the labeled training examples such that the proportion of their non-predominant classes is below a fixed threshold stands for clustering consistency. In the second step, a classifier is trained by minimizing a margin empirical loss over the labeled training set and a penalization term measuring the disability of the learner to predict the k predominant classes of the identified clusters. The resulting data-dependent generalization error bound involves the margin distribution of the classifier, the stability of the clustering technique used in the first step and Rademacher complexity terms corresponding to partially labeled training data. Our theoretical result exhibit convergence rates extending those proposed in the literature for the binary case, and experimental results on different multi-class classification problems show empirical evidence that supports the theory.","tags":null,"title":"Rademacher Complexity Bounds for a Penalized Multi-class Semi-supervised Algorithm","type":"publication"},{"authors":["Yury Maximov","Massih Amini","Zaid Harchaoui"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"914257ca652ab5eb0aad62df26834642","permalink":"https://yury-maximov.github.io/publication/c16-zaid-2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/c16-zaid-2018/","section":"publication","summary":"We propose Rademacher complexity bounds for multi-class classifiers trained with a two-step semi-supervised model. In the first step, the algorithm partitions the partially labeled data and then identifies dense clusters containing \\\\(\\kappa\\\\) predominant classes using the labeled training examples such that the proportion of their non-predominant classes is below a fixed threshold stands for clustering consistency. In the second step, a classifier is trained by minimizing a margin empirical loss over the labeled training set and a penalization term measuring the disability of the learner to predict the \\\\(\\kappa\\\\) predominant classes of the identified clusters. The resulting data-dependent generalization error bound involves the margin distribution of the classifier, the stability of the clustering technique used in the first step and Rademacher complexity terms corresponding to partially labeled training data. Our theoretical result exhibit convergence rates extending those proposed in the literature for the binary case, and experimental results show empirical evidence that supports the theory.","tags":null,"title":"Rademacher Complexity Bounds for a Penalized Multiclass Semi-Supervised Algorithm","type":"publication"},{"authors":["Bikash Joshi","Massih Amini","Ioannis Partalas","Franck Iutzeler","Yury Maximov"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"2325f7a76aabd8777ab1dabf5d38415f","permalink":"https://yury-maximov.github.io/publication/c10-bikash-2017/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/c10-bikash-2017/","section":"publication","summary":"We address the problem of multi-class classification in the case where the number of classes is very large. We propose a double sampling strategy on top of a multi-class to binary reduction strategy, which transforms the original multi-class problem into a binary classification problem over pairs of examples. The aim of the sampling strategy is to overcome the curse of long-tailed class distributions exhibited in majority of large-scale multi-class classification problems and to reduce the number of pairs of examples in the expanded data. We show that this strategy does not alter the consistency of the empirical risk minimization principle defined over the double sample reduction. Experiments are carried out on DMOZ and Wikipedia collections with 10,000 to 100,000 classes where we show the efficiency of the proposed approach in terms of training and prediction time, memory consumption, and predictive performance with respect to state-of-the-art approaches.","tags":null,"title":"Aggressive Sampling for Multi-class to Binary Reduction with Applications to Text Classification","type":"publication"},{"authors":["Valerya Kovaleva","Yury Maximov","Sergei Nechaev","Olga Valba"],"categories":null,"content":"","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"e5557873c659dee0d47087d4b642dfb8","permalink":"https://yury-maximov.github.io/publication/j12-lera-2017/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/publication/j12-lera-2017/","section":"publication","summary":"In this paper we investigate the eigenvalue statistics of exponentially weighted ensembles of full binary trees and p-branching star graphs. We show that spectral densities of corresponding adjacency matrices demonstrate peculiar ultrametric structure inherent to sparse systems. In particular, the tails of the distribution for binary trees share the 'Lifshitz singularity' emerging in the one-dimensional localization, while the spectral statistics of p-branching star-like graphs is less universal, being strongly dependent on p. The hierarchical structure of spectra of adjacency matrices is interpreted as sets of resonance frequencies, that emerge in ensembles of fully branched tree-like systems, known as dendrimers. However, the relaxational spectrum is not determined by the cluster topology, but has rather the number-theoretic origin, reflecting the peculiarities of the rare-event statistics typical for one-dimensional systems with a quenched structural disorder. The similarity of spectral densities of an individual dendrimer and of an ensemble of linear chains with exponential distribution in lengths, demonstrates that dendrimers could be served as simple disorder-less toy models of one-dimensional systems with quenched disorder.","tags":null,"title":"Peculiar spectral statistics of ensembles of trees and star-like graphs","type":"publication"},{"authors":["Dmitry Sidorchuk","Ivan Konovalenko","Sergei Gladilin","Yury Maximov"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"59195690d0db08747ab0d4f61711064c","permalink":"https://yury-maximov.github.io/publication/c09-ivan-2016/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/c09-ivan-2016/","section":"publication","summary":"We study a technique for improving visualization quality of noisy multispectral images. Contrast form visualization approach is considered, which guarantees a non-zero contrast in the output image when there is a difference between the spectra of the object and the background in the input image. The improvement is based on channel weighting according to estimation of the noise level. We show this approach to reduce noise in color visualization of real multispectral images. The low-noise visualizations are demonstrated to be more comprehensive to a human on examples from a publicly available dataset of Earth surface images. Noise variance estimation needed for weighting uses the method proposed earlier by the authors. The validation dataset consists of publicly available images of Earth surface.","tags":null,"title":"Noise estimation for color visualization of multispectral images","type":"publication"},{"authors":["Yury Maximov","Daria Reshetova"],"categories":null,"content":"","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"248b9e9a55650501fddb9e07c127626b","permalink":"https://yury-maximov.github.io/publication/j07-dasha-2016/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/publication/j07-dasha-2016/","section":"publication","summary":"We consider a problem of risk estimation for large-margin multi-class classifiers. We propose a novel risk bound for the multi-class classification problem. The bound involves the marginal distribution of the classifier and the Rademacher complexity of the hypothesis class. We prove that our bound is tight in the number of classes. Finally, we compare our bound with the related ones and provide a simplified version of the bound for the multi-class classification with kernel based hypotheses.","tags":null,"title":"Tight risk bounds for multi-class margin classifiers","type":"publication"},{"authors":["Galina Iofina","Yury Maximov"],"categories":null,"content":"","date":1464739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464739200,"objectID":"e03441c61d412fa764b3a7537ddd0087","permalink":"https://yury-maximov.github.io/publication/j06-galya-2016/","publishdate":"2016-06-01T00:00:00Z","relpermalink":"/publication/j06-galya-2016/","section":"publication","summary":"The problems of learning a good similarity function between objects naturally arise in machine learning, pattern recognition and data mining such as clustering, community detection or metric learning as well. We focus on the special case of this problem, where similarity function is completely determined by the hidden object classes. But we assume that no information about object labels is accessible on a training stage. The main contribution of the paper is two-stage algorithm assigns to each object its class label and provides a similarity function based on this assignment. We provide risk bounds and empirical evaluation in support of our algorithm. As a consequence of our analysis we provide a new tradeoff between empirical error of a multi-class classifier and its generalization error.","tags":null,"title":"Reduction based similarity learning for high dimensional problems","type":"publication"},{"authors":["Aleksandr Gasnikov","Pavel Dvurechensky","Yury Dorn","Yury Maximov"],"categories":null,"content":"","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"08d814aa29e956227942925d157270b5","permalink":"https://yury-maximov.github.io/publication/j08-dorn-2016/","publishdate":"2016-03-01T00:00:00Z","relpermalink":"/publication/j08-dorn-2016/","section":"publication","summary":"In this work we propose new computational methods for transportation equilibrium problems. For Beckmann's equilibrium model we consider Frank–Wolfe algorithm in a view of modern complexity results for this method. For Stable Dynamic model we propose new methods. First approach based on mirror descent scheme with Euclidean prox-structure for dual problem and randomization of a sum trick. Second approach based on Nesterov's smoothing technique of dual problem in form of Dorn–Nesterov and new implementation of randomized block-component gradient descent algorithm.","tags":null,"title":"Numerical methods for the problem of traffic flow equilibrium in the Beckmann and the stable dynamic models","type":"publication"},{"authors":["Yury Maximov"],"categories":null,"content":"","date":1425168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425168000,"objectID":"771ec73f3f960f64e1620af6ef11b9af","permalink":"https://yury-maximov.github.io/publication/j05-cmmp-2015/","publishdate":"2015-03-01T00:00:00Z","relpermalink":"/publication/j05-cmmp-2015/","section":"publication","summary":"It was previously established that almost every Boolean function of n variables with k zeros, where \\\\(k\\\\) is at most \\\\(\\log_2 n –\\log_2\\log_2 n + 1\\\\), can be associated with a Boolean function of \\\\(2^{k–1}–1\\\\) variables with k zeros (complete function) such that the complexity of implementing the original function in the class of disjunctive normal forms is determined only by the complexity of implementing the complete function. An asymptotically tight bound is obtained for the minimum possible number of literals contained in the disjunctive normal forms of the complete function.","tags":null,"title":"Shortest and minimal disjunctive normal forms of complete functions","type":"publication"},{"authors":["Yury Maximov"],"categories":null,"content":"","date":1362096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362096000,"objectID":"9f108b0c147da0599fc0138aa632cbf4","permalink":"https://yury-maximov.github.io/publication/j04-cmmp-2013/","publishdate":"2013-03-01T00:00:00Z","relpermalink":"/publication/j04-cmmp-2013/","section":"publication","summary":"The problem of constructing simple disjunctive normal forms (DNFs) of Boolean functions with a small number of zeros is considered. The problem is of interest in the complexity analysis of Boolean functions and in its applications to data analysis. The method used is a further development of the reduction approach to the construction of DNFs of Boolean functions. A key idea of the reduction method is that a Boolean function is represented as a disjunction of Boolean functions with fewer zeros. In a number of practically important cases, this technique makes it possible to considerably reduce the complexity of DNF implementations of Boolean functions.","tags":null,"title":"Implementation of Boolean functions with a bounded number of zeros by disjunctive normal forms","type":"publication"},{"authors":["Yury Maximov"],"categories":null,"content":"","date":1354320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1354320000,"objectID":"03b7911a6f76e9a45a0443bd3b98ec2e","permalink":"https://yury-maximov.github.io/publication/j03-danb-2012/","publishdate":"2012-12-01T00:00:00Z","relpermalink":"/publication/j03-danb-2012/","section":"publication","summary":"This paper proposes novel algorithms to lower bound complexities of disjunctive normal forms of Boolean functions. The algorithms outperform Shannon's counting argument and construct disjunctive normal forms with complexities (length, rank, etc.) that match known upper bounds if a function equals zero on a sufficiently small number of points.","tags":null,"title":"Comparative analysis of the complexity of boolean functions with a small number of zeros","type":"publication"},{"authors":["Yury Maximov"],"categories":null,"content":"","date":1330560000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330560000,"objectID":"fe179fe83f44a81c94833e4b85360f39","permalink":"https://yury-maximov.github.io/publication/j02-dana-2012/","publishdate":"2012-03-01T00:00:00Z","relpermalink":"/publication/j02-dana-2012/","section":"publication","summary":"In this paper, we propose sub-optimal implementation of Boolean functions by disjunctive normal forms if the number of zeros of a function is sufficiently small with respect to the number of input variables. We also prove that the constructed disjunctive form provides a reasonable approximation to the optimal one regarding the number of conjunctions and literals.","tags":null,"title":"Simple disjunctive normal forms of Boolean functions with a restricted number of zeros","type":"publication"},{"authors":["Yury Maximov"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"479c86267066e8f8b8c7829586e8689f","permalink":"https://yury-maximov.github.io/publication/j01-cmmp-2009/","publishdate":"2009-01-01T00:00:00Z","relpermalink":"/publication/j01-cmmp-2009/","section":"publication","summary":"Algebras over estimation algorithms in the set of regular problems with nonoverlapping classes are considered. A correctness criterion for the arbitrary degree algebraic closure of the model of estimation algorithms in the classification problems of this type is proposed; this criterion can be efficiently verified. An estimate of the minimal degree of the algebraic closure that is sufficient for constructing a correct classifier in an arbitrary regular problem with nonoverlapping classes is found.","tags":null,"title":"Correct algebras over estimation algorithms in the set of regular recognition problems with nonoverlapping classes","type":"publication"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":959864400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":959864400,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://yury-maximov.github.io/talk/example-talk/","publishdate":"2000-08-08T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://yury-maximov.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]